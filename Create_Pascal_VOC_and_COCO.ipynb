{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Create_Pascal_VOC_and_COCO.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZcaTX42AhsJ"
      },
      "source": [
        "# Global Wheat Detection Annotations\n",
        "\n",
        "Creates Pascal VOC (XML) and COCO (JSON) annotations for the [Global Wheat Detection](https://www.kaggle.com/c/global-wheat-detection) challenge.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0BWaVJUDiiI"
      },
      "source": [
        "Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjtnqfKv-5ZA"
      },
      "source": [
        "import sys, os, re, time, glob, random, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "!pip install -q pascal-voc-writer\n",
        "from pascal_voc_writer import Writer\n",
        "\n",
        "!wget -q https://raw.githubusercontent.com/Tony607/voc2coco/master/voc2coco.py\n",
        "from voc2coco import *"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "994SEdR2Doqw"
      },
      "source": [
        "## Import and Preprocess Data\n",
        "\n",
        "This notebook can run with or without the `global-wheat-detection.zip` file containing all the competition data. However, the file can be found [here](https://www.kaggle.com/c/global-wheat-detection/data) by selecting Download All. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQsy3YYzdAvI",
        "cellView": "form"
      },
      "source": [
        "#@markdown Select only if `global-wheat-detection.zip` is in the working directory\n",
        "use_jpg_dataset = False #@param {type: 'boolean'}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOEl5_sAkADl",
        "outputId": "472f4454-a532-4040-81d1-5056a6c5c41e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "if not os.path.isdir('data'):\n",
        "    !mkdir data\n",
        "if use_jpg_dataset and os.path.isfile('global-wheat-detection.zip'):\n",
        "    !unzip -q global-wheat-detection.zip -d data\n",
        "    !mv data/train data/images\n",
        "    fnames = glob.glob('data/images/*.jpg')\n",
        "    ids_from_files = [fn.split('/')[-1].split('.')[0] for fn in fnames] # ids of all images in the orig train set\n",
        "    df=pd.read_csv('/content/data/train.csv')\n",
        "else:\n",
        "    !wget -q https://raw.githubusercontent.com/reyvaz/Global-Wheat-XML-and-COCO-Annotations/master/data/ids_from_files.txt\n",
        "    !wget -q https://raw.githubusercontent.com/reyvaz/Global-Wheat-XML-and-COCO-Annotations/master/data/train.csv\n",
        "    ids_from_files = [line.rstrip('\\n') for line in open('ids_from_files.txt')]\n",
        "    df=pd.read_csv('train.csv')\n",
        "\n",
        "df.head(3)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>bbox</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "      <td>[834.0, 222.0, 56.0, 36.0]</td>\n",
              "      <td>usask_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "      <td>[226.0, 548.0, 130.0, 58.0]</td>\n",
              "      <td>usask_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "      <td>[377.0, 504.0, 74.0, 160.0]</td>\n",
              "      <td>usask_1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    image_id  width  height                         bbox   source\n",
              "0  b6ab77fd7   1024    1024   [834.0, 222.0, 56.0, 36.0]  usask_1\n",
              "1  b6ab77fd7   1024    1024  [226.0, 548.0, 130.0, 58.0]  usask_1\n",
              "2  b6ab77fd7   1024    1024  [377.0, 504.0, 74.0, 160.0]  usask_1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SqfT2GdFOky"
      },
      "source": [
        "The original data, as it appears in the `bbox` column is in the format\n",
        "`x_min, y_min, x_dist, y_dist`. Below will convert to `x_min, y_min, x_max, y_max`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhiRn7lE-5gW",
        "outputId": "4704ee00-4a1f-4e14-f405-4aa2a4c05955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "bbox_to_lists = lambda x: x.strip('[]').split(', ')\n",
        "\n",
        "df['bbox_lists'] = [bbox_to_lists(row) for row in df.bbox]\n",
        "df['x_min'] = [int(float(row[0])) for row in df.bbox_lists]\n",
        "df['y_min'] = [int(float(row[1])) for row in df.bbox_lists]\n",
        "df['x_dist'] = [int(float(row[2])) for row in df.bbox_lists]\n",
        "df['y_dist'] = [int(float(row[3])) for row in df.bbox_lists]\n",
        "df['x_max'] = df.x_min + df.x_dist\n",
        "df['y_max'] = df.y_min + df.y_dist\n",
        "df = df[df.columns[[0,6,7,10,11]]]\n",
        "\n",
        "df.head(3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>x_min</th>\n",
              "      <th>y_min</th>\n",
              "      <th>x_max</th>\n",
              "      <th>y_max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>834</td>\n",
              "      <td>222</td>\n",
              "      <td>890</td>\n",
              "      <td>258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>226</td>\n",
              "      <td>548</td>\n",
              "      <td>356</td>\n",
              "      <td>606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>377</td>\n",
              "      <td>504</td>\n",
              "      <td>451</td>\n",
              "      <td>664</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    image_id  x_min  y_min  x_max  y_max\n",
              "0  b6ab77fd7    834    222    890    258\n",
              "1  b6ab77fd7    226    548    356    606\n",
              "2  b6ab77fd7    377    504    451    664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmm6WTWnGaTn"
      },
      "source": [
        "The image dataset (or the `ids_from_files.txt`) contains more files than those listed in the annotations dataframe (`train.csv`). The difference, is that the files include images with no annotations (i.e. they do not contain the object) and are thus not listed in the `train.csv`. \n",
        "\n",
        "I will include these images, but they will be processed separately so they can be excluded from training if needed. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5CqEOVt-5n_",
        "outputId": "8b741537-671d-4566-baf8-36d2214d2768",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_images = len(ids_from_files)\n",
        "unique_ids = np.unique(df.image_id) # ids of all images in the dataframe\n",
        "images_no_bbox = list(set(ids_from_files) - set(unique_ids)) # difference are images with no bbox (i.e. no object)\n",
        "len(unique_ids), n_images, len(images_no_bbox)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3373, 3422, 49)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmKHu7Ri-5s7"
      },
      "source": [
        "def list_to_text_file(id_list, dest_path):\n",
        "    with open(dest_path, 'w') as f: \n",
        "        for item in id_list:\n",
        "            f.write(\"%s\\n\" % item) \n",
        "    return None"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPE5mvtkbsJl"
      },
      "source": [
        "## Creating XML (Pascal VOC) Annotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0NGHxfm-5_a"
      },
      "source": [
        "LABEL = 'wheat'\n",
        "width, height = 1024, 1024"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MvzflxMD74E"
      },
      "source": [
        "All xml files will be in one directory. For cross-validation, only additional text files as the one below with the alternative train/validation splits (i.e. K-folds) would be needed. These can be produced when training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crVm6icuD_mV"
      },
      "source": [
        "train_ids, valid_ids = train_test_split(ids_from_files, train_size = 0.8, random_state = 8)\n",
        "list_to_text_file(train_ids, 'data/train.txt')\n",
        "list_to_text_file(valid_ids, 'data/val.txt')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fflhLg8n-5yw"
      },
      "source": [
        "jpegs_path = 'data/images'\n",
        "xml_annotations_path = 'data/xml_annotations'\n",
        "# create dir to place xml (pascal voc annotations)\n",
        "!mkdir {xml_annotations_path}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKyPAO2XG5VA"
      },
      "source": [
        "def xml_from_id(id):\n",
        "    # creates an xml (Pascal Voc format) file for an image file\n",
        "    # id should be extracted from the original image file name\n",
        "    im_df=df[df.image_id == id].reset_index()\n",
        "    path_img = '{}/{}.jpg'.format('data/VOCdevkit/VOC2007/JPEGImages', id)\n",
        "    path_xml = '{}/{}.xml'.format(xml_annotations_path, id)\n",
        "\n",
        "    writer = Writer(path_img, width, height)\n",
        "    if len(im_df) > 0:\n",
        "        for idx in im_df.index:\n",
        "            anot = [LABEL] + im_df[['x_min', \n",
        "                            'y_min', 'x_max', 'y_max']].iloc[idx].tolist()\n",
        "            writer.addObject(*anot)\n",
        "    writer.save(path_xml)\n",
        "    return None"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lSZ1x0X-5l8",
        "outputId": "e7746480-a9bb-4a56-9831-afafc6f16583",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "create_xml_files =  True #@param {type:\"boolean\"}\n",
        "if create_xml_files:\n",
        "    # Create the XML files for training images\n",
        "    _ = [xml_from_id(id) for id in ids_from_files]\n",
        "\n",
        "    !ls {xml_annotations_path} -1 | wc -l\n",
        "    !ls {xml_annotations_path}/*.xml | head -5\n",
        "    !head -7 {xml_annotations_path}/366187e59.xml"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3422\n",
            "data/xml_annotations/00333207f.xml\n",
            "data/xml_annotations/005b0d8bb.xml\n",
            "data/xml_annotations/006a994f7.xml\n",
            "data/xml_annotations/00764ad5d.xml\n",
            "data/xml_annotations/00b5c6764.xml\n",
            "<annotation>\n",
            "    <folder>JPEGImages</folder>\n",
            "    <filename>366187e59.jpg</filename>\n",
            "    <path>/content/data/VOCdevkit/VOC2007/JPEGImages/366187e59.jpg</path>\n",
            "    <source>\n",
            "        <database>Unknown</database>\n",
            "    </source>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtGGN--bLxtY"
      },
      "source": [
        "## Creating COCO (JSON) Annotations\n",
        "\n",
        "This section creates the COCO Dataset from the XML files created above\n",
        "    \n",
        "The function below has been adapted from the `voc2coco.py` script \n",
        "- To include a generated integer ID for each image in the .json files.\n",
        "    - Useful when using pycocotools.\n",
        "- To generate a segmentation mask. Segmentation info is inferred from the bboxes.\n",
        "    - This is required by some detectors (i.e. HTC DetectoRS).\n",
        "- To eliminate subtracting 1 from the min values of x and y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDjuKZGDLzQr",
        "outputId": "9bba7789-c50e-487c-ee72-00d2f24996dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "images_with_bbox = list(set(ids_from_files) - set(images_no_bbox)) # same as unique_ids array\n",
        "len(ids_from_files), len(images_with_bbox), len(images_no_bbox)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3422, 3373, 49)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYCCAti4LSaE"
      },
      "source": [
        "**COCO data splits**\n",
        "\n",
        "- will create .80-.20, .90-.10 train/val splits for `images_with_bbox` \n",
        "- all `images_no_bbox` will be separated, and included when needed with the train set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANuHsAi0KqM9"
      },
      "source": [
        "train_ids_80, valid_ids_20 = train_test_split(images_with_bbox, train_size = 0.8, random_state = 8)\n",
        "train_ids_10, valid_ids_10 = train_test_split(valid_ids_20, train_size = 0.5, random_state = 8)\n",
        "train_ids_90 = train_ids_80 + train_ids_10\n",
        "train_ids_90_plus = train_ids_90 + images_no_bbox\n",
        "random.shuffle(train_ids_90_plus)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aB802F_KrpK",
        "outputId": "b6a3526b-0982-4427-97ee-2f70c57cf9be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(train_ids_80), len(valid_ids_20), len(valid_ids_10), len(train_ids_90), len(train_ids_90_plus)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2698, 675, 338, 3035, 3084)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a93EFfjNNqbP"
      },
      "source": [
        "#@markdown saving id lists to text files\n",
        "list_to_text_file(train_ids_80, 'data/train_ids_80.txt')\n",
        "list_to_text_file(valid_ids_20, 'data/valid_ids_20.txt')\n",
        "list_to_text_file(train_ids_90, 'data/train_ids_90.txt')\n",
        "list_to_text_file(valid_ids_10, 'data/valid_ids_10.txt')\n",
        "list_to_text_file(train_ids_90_plus, 'data/train_ids_90_plus.txt')\n",
        "list_to_text_file(images_no_bbox, 'data/images_no_bbox.txt')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAUQcj7BQKpK",
        "cellView": "form"
      },
      "source": [
        "#@markdown Convert XML to COCO Function. Edited from Tony's (Chenwei) Version.\n",
        "def convert(xml_files, json_file, start_index):\n",
        "    json_dict = {\"images\": [], \"type\": \"instances\", \"annotations\": [], \"categories\": []}\n",
        "    categories = {\"wheat\": 1}\n",
        "    bnd_id = START_BOUNDING_BOX_ID\n",
        "\n",
        "    for indx, xml_file in enumerate(xml_files):\n",
        "        image_id = indx + start_index\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        path = get(root, \"path\")\n",
        "        if len(path) == 1:\n",
        "            filename = os.path.basename(path[0].text)\n",
        "        elif len(path) == 0:\n",
        "            filename = get_and_check(root, \"filename\", 1).text\n",
        "        else:\n",
        "            raise ValueError(\"%d paths found in %s\" % (len(path), xml_file))\n",
        "        size = get_and_check(root, \"size\", 1)\n",
        "        width = int(get_and_check(size, \"width\", 1).text)\n",
        "        height = int(get_and_check(size, \"height\", 1).text)\n",
        "        image = {\n",
        "            \"file_name\": filename,\n",
        "            \"height\": height,\n",
        "            \"width\": width,\n",
        "            \"id\": image_id,\n",
        "        }\n",
        "        json_dict[\"images\"].append(image)\n",
        "\n",
        "        for obj in get(root, \"object\"):\n",
        "            category = get_and_check(obj, \"name\", 1).text\n",
        "            if category not in categories:\n",
        "                new_id = len(categories)\n",
        "                categories[category] = new_id\n",
        "            category_id = categories[category]\n",
        "            bndbox = get_and_check(obj, \"bndbox\", 1)\n",
        "            xmin = int(get_and_check(bndbox, \"xmin\", 1).text)\n",
        "            ymin = int(get_and_check(bndbox, \"ymin\", 1).text)\n",
        "            xmax = int(get_and_check(bndbox, \"xmax\", 1).text)\n",
        "            ymax = int(get_and_check(bndbox, \"ymax\", 1).text)\n",
        "            assert xmax > xmin\n",
        "            assert ymax > ymin\n",
        "            o_width = abs(xmax - xmin)\n",
        "            o_height = abs(ymax - ymin)\n",
        "            ann = {\n",
        "                \"area\": o_width * o_height,\n",
        "                \"iscrowd\": 0,\n",
        "                \"image_id\": image_id,\n",
        "                \"bbox\": [xmin, ymin, o_width, o_height],\n",
        "                \"category_id\": category_id,\n",
        "                \"id\": bnd_id,\n",
        "                \"ignore\": 0,\n",
        "                \"segmentation\": [[xmin,ymin, xmin,ymax, xmax,ymax, xmax,ymin]],\n",
        "            }\n",
        "            json_dict[\"annotations\"].append(ann)\n",
        "            bnd_id = bnd_id + 1\n",
        "\n",
        "    for cate, cid in categories.items():\n",
        "        cat = {\"supercategory\": \"none\", \"id\": cid, \"name\": cate}\n",
        "        json_dict[\"categories\"].append(cat)\n",
        "\n",
        "    os.makedirs(os.path.dirname(json_file), exist_ok=True)\n",
        "    json_fp = open(json_file, \"w\")\n",
        "    json_str = json.dumps(json_dict)\n",
        "    json_fp.write(json_str)\n",
        "    json_fp.close()\n",
        "\n",
        "\n",
        "# break down of segmentation\n",
        "# \"segmentation\" = [x_min, y_min,  # top-left\n",
        "#                   x_min, y_max,  # bottom-left\n",
        "#                   x_max, y_max,  # bottom-right\n",
        "#                   x_max, y_min]. # top-right"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ5e3HiNQK2k"
      },
      "source": [
        "xml_files_train_80 = [xml_annotations_path + '/' + id + '.xml' for id in train_ids_80]\n",
        "xml_files_train_90 = [xml_annotations_path + '/' + id + '.xml' for id in train_ids_90]\n",
        "xml_files_train_90_plus = [xml_annotations_path + '/' + id + '.xml' for id in train_ids_90_plus]\n",
        "\n",
        "xml_files_val_20 = [xml_annotations_path +'/' + id + '.xml' for id in valid_ids_20]\n",
        "xml_files_val_10 = [xml_annotations_path +'/' + id + '.xml' for id in valid_ids_10]\n",
        "xml_files_no_bb = [xml_annotations_path +'/' + id + '.xml' for id in images_no_bbox]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k689i5b0QK6-"
      },
      "source": [
        "!mkdir data/coco\n",
        "json_file_train_80 = './data/coco/train_80.json'\n",
        "json_file_val_20 = './data/coco/val_20.json'\n",
        "json_file_train_90 = './data/coco/train_90.json'\n",
        "json_file_val_10 = './data/coco/val_10.json'\n",
        "json_file_train_90_plus = './data/coco/train_90_plus.json'\n",
        "json_file_no_bb = './data/coco/no_bb.json'"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO8feomcQK-6"
      },
      "source": [
        "_ = convert(xml_files_train_80, json_file_train_80, start_index = 0)\n",
        "start_index_val = len(xml_files_train_80)\n",
        "_ = convert(xml_files_val_20, json_file_val_20, start_index = start_index_val)\n",
        "_ = convert(xml_files_train_90, json_file_train_90, start_index = 0)\n",
        "_ = convert(xml_files_train_90_plus, json_file_train_90_plus, start_index = 0)\n",
        "\n",
        "start_index_bb = len(xml_files_train_90)\n",
        "_ = convert(xml_files_no_bb, json_file_no_bb, start_index = start_index_bb)\n",
        "\n",
        "start_index_val = len(xml_files_train_90_plus)\n",
        "_ = convert(xml_files_val_10, json_file_val_10, start_index = start_index_val)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM0bA9TvS5uX"
      },
      "source": [
        "val_json = json.load(open('/content/data/coco/val_20.json'))\n",
        "#val_json # uncomment to check the annotations file"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orDrsagyIRkI"
      },
      "source": [
        "## Compressing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S22e7HlSHlH"
      },
      "source": [
        "!mkdir annotations\n",
        "!mv data/xml_annotations annotations\n",
        "!mv data/coco annotations\n",
        "!mv data/*txt annotations\n",
        "!zip -rq annotations.zip annotations"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22JKHH7XTgb5",
        "outputId": "926319fc-c0bf-4aa5-86fb-4eaa63437420",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls annotations*"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "annotations.zip\n",
            "\n",
            "annotations:\n",
            "coco\t\t    train_ids_90_plus.txt  valid_ids_10.txt  xml_annotations\n",
            "images_no_bbox.txt  train_ids_90.txt\t   valid_ids_20.txt\n",
            "train_ids_80.txt    train.txt\t\t   val.txt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}